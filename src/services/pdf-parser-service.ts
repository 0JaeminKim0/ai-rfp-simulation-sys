// PDF/ë¬¸ì„œ íŒŒì‹± ì„œë¹„ìŠ¤ - PDF.js + OCR + LLM

import { PDFDocument } from 'pdf-lib'

export class PdfParserService {
  
  /**
   * PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
   */
  async extractTextFromPdf(
    pdfBuffer: ArrayBuffer | Uint8Array,
    fileName: string
  ): Promise<{
    text: string
    pages: Array<{
      page_number: number
      content: string
      word_count: number
    }>
    metadata: {
      title?: string
      author?: string
      subject?: string
      creator?: string
      creation_date?: string
      modification_date?: string
      page_count: number
      file_size: number
    }
    extraction_method: 'pdf-parse' | 'pdf-lib' | 'fallback'
  }> {
    
    try {
      console.log(`ğŸ“„ PDF íŒŒì‹± ì‹œì‘: ${fileName} (${pdfBuffer.byteLength} bytes)`)
      
      // Railway í™˜ê²½ì—ì„œ pdf-parse ì‚¬ìš© ì‹œë„
      try {
        const pdfParse = require('pdf-parse')
        const uint8Buffer = Buffer.from(pdfBuffer)
        
        console.log('ğŸš€ pdf-parse ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ì¤‘...')
        const pdfData = await pdfParse(uint8Buffer)
        
        console.log(`âœ… PDF íŒŒì‹± ì„±ê³µ: ${pdfData.text.length}ì, ${pdfData.numpages}í˜ì´ì§€ (pdf-parse)`)
        
        // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ë¶„í•  ì‹œë„
        const textPerPage = Math.ceil(pdfData.text.length / pdfData.numpages)
        const pages = []
        
        for (let i = 0; i < pdfData.numpages; i++) {
          const start = i * textPerPage
          const end = Math.min((i + 1) * textPerPage, pdfData.text.length)
          const pageContent = pdfData.text.substring(start, end).trim()
          
          if (pageContent.length > 0) {
            pages.push({
              page_number: i + 1,
              content: pageContent,
              word_count: pageContent.split(/\s+/).length
            })
          }
        }
        
        const metadata = {
          title: pdfData.info?.Title || undefined,
          author: pdfData.info?.Author || undefined,
          subject: pdfData.info?.Subject || undefined,
          creator: pdfData.info?.Creator || undefined,
          creation_date: pdfData.info?.CreationDate || undefined,
          modification_date: pdfData.info?.ModDate || undefined,
          page_count: pdfData.numpages,
          file_size: pdfBuffer.byteLength
        }

        return {
          text: pdfData.text,
          pages: pages,
          metadata: metadata,
          extraction_method: 'pdf-parse'
        }
        
      } catch (pdfParseError) {
        console.log(`âš ï¸ pdf-parse ì‹¤íŒ¨, pdf-lib ëŒ€ì•ˆ ì‹œë„: ${pdfParseError.message}`)
        return this.extractWithPdfLib(pdfBuffer, fileName)
      }
      
    } catch (error) {
      console.error('âŒ PDF íŒŒì‹± ì™„ì „ ì‹¤íŒ¨:', error)
      throw new Error(`PDF íŒŒì‹± ì˜¤ë¥˜: ${error.message}`)
    }
  }
  
  /**
   * PDF-libì„ ì‚¬ìš©í•œ ëŒ€ì•ˆ íŒŒì‹±
   */
  private async extractWithPdfLib(
    pdfBuffer: ArrayBuffer | Uint8Array,
    fileName: string
  ): Promise<{
    text: string
    pages: Array<{
      page_number: number
      content: string
      word_count: number
    }>
    metadata: {
      title?: string
      author?: string
      subject?: string
      creator?: string
      creation_date?: string
      modification_date?: string
      page_count: number
      file_size: number
    }
    extraction_method: 'pdf-lib' | 'fallback'
  }> {
    
    try {
      console.log(`ğŸ”„ pdf-lib ë°©ì‹ìœ¼ë¡œ PDF íŒŒì‹±: ${fileName}`)
      
      // PDF ë¬¸ì„œ ë¡œë“œ
      const pdfDoc = await PDFDocument.load(pdfBuffer)
      const pageCount = pdfDoc.getPageCount()
      
      // ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
      const metadata = {
        title: pdfDoc.getTitle() || undefined,
        author: pdfDoc.getAuthor() || undefined,
        subject: pdfDoc.getSubject() || undefined,
        creator: pdfDoc.getCreator() || undefined,
        creation_date: pdfDoc.getCreationDate()?.toISOString() || undefined,
        modification_date: pdfDoc.getModificationDate()?.toISOString() || undefined,
        page_count: pageCount,
        file_size: pdfBuffer.byteLength
      }

      console.log(`ğŸ“‹ PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ: ${pageCount}í˜ì´ì§€`)

      // íŒ¨í„´ ë§¤ì¹­ ë°©ì‹ í…ìŠ¤íŠ¸ ì¶”ì¶œ
      const extractionResult = await this.extractWithFallbackMethod(pdfBuffer)
      
      const pages = extractionResult.pages.map((content, index) => ({
        page_number: index + 1,
        content: content,
        word_count: content.split(/\s+/).length
      }))

      const allText = pages.map(page => page.content).join('\n\n')

      console.log(`ğŸ“‹ PDF-lib í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: ${allText.length}ì`)

      return {
        text: allText,
        pages: pages,
        metadata: metadata,
        extraction_method: extractionResult.method
      }
      
    } catch (error) {
      console.error('âŒ PDF-libë„ ì‹¤íŒ¨:', error)
      throw new Error(`PDF íŒŒì‹± ì™„ì „ ì‹¤íŒ¨: ${error.message}`)
    }
  }

  /**
   * ëŒ€ì•ˆ ë°©ì‹ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Cloudflare Workers í˜¸í™˜)
   */
  private async extractWithFallbackMethod(pdfBuffer: ArrayBuffer): Promise<{
    pages: string[]
    method: 'pdf-lib' | 'fallback'
  }> {
    
    try {
      // PDF êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ ê°ì²´ë¥¼ ì°¾ì•„ ì¶”ì¶œí•˜ëŠ” ê°„ë‹¨í•œ ë°©ì‹
      const uint8Array = new Uint8Array(pdfBuffer)
      const pdfString = new TextDecoder('utf-8', { fatal: false }).decode(uint8Array)
      
      // PDF ë‚´ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ íŒ¨í„´ ë§¤ì¹­
      const textPatterns = [
        /BT\s+.*?ET/gs,  // ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¸”ë¡
        /\(([^)]+)\)\s*Tj/g,  // í…ìŠ¤íŠ¸ í‘œì‹œ ëª…ë ¹
        /\[([^\]]+)\]\s*TJ/g,  // ë°°ì—´ í˜•íƒœ í…ìŠ¤íŠ¸
        /\/F\d+\s+\d+\s+Tf\s+([^(]+)/g  // í°íŠ¸ ì„¤ì • í›„ í…ìŠ¤íŠ¸
      ]

      let extractedTexts = []
      
      for (const pattern of textPatterns) {
        const matches = pdfString.match(pattern)
        if (matches) {
          extractedTexts.push(...matches)
        }
      }

      // ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì •ì œ
      const cleanTexts = extractedTexts
        .map(text => this.cleanPdfText(text))
        .filter(text => text.length > 5) // ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œê±°
      
      // í˜ì´ì§€ êµ¬ë¶„ ì‹œë„ (ì™„ì „í•˜ì§€ ì•ŠìŒ)
      const combinedText = cleanTexts.join('\n')
      const estimatedPages = this.estimatePageBreaks(combinedText)
      
      return {
        pages: estimatedPages.length > 0 ? estimatedPages : [combinedText],
        method: 'fallback'
      }
      
    } catch (error) {
      console.error('ëŒ€ì•ˆ ë°©ì‹ ì¶”ì¶œ ì‹¤íŒ¨:', error)
      
      // ìµœí›„ ìˆ˜ë‹¨: ë°”ì´ë„ˆë¦¬ì—ì„œ ì¼ë°˜ í…ìŠ¤íŠ¸ íŒ¨í„´ ì°¾ê¸°
      const uint8Array = new Uint8Array(pdfBuffer)
      const fallbackText = this.extractPlainTextFromBinary(uint8Array)
      
      return {
        pages: [fallbackText],
        method: 'fallback'
      }
    }
  }

  /**
   * PDF í…ìŠ¤íŠ¸ ì •ì œ
   */
  private cleanPdfText(rawText: string): string {
    return rawText
      // PDF ëª…ë ¹ì–´ ì œê±°
      .replace(/BT|ET|Tj|TJ|Tf|Td|TD/g, '')
      // ê´„í˜¸ ì œê±°
      .replace(/[()]/g, '')
      // ëŒ€ê´„í˜¸ì™€ ë‚´ìš© ì •ë¦¬
      .replace(/\[|\]/g, '')
      // ìˆ«ìë§Œìœ¼ë¡œ ëœ ë¼ì¸ ì œê±° (ì¢Œí‘œê°’ ë“±)
      .replace(/^\d+(\.\d+)?\s*$/gm, '')
      // ì—°ì† ê³µë°± ì •ë¦¬
      .replace(/\s+/g, ' ')
      // íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
      .replace(/[^\w\sê°€-í£.,!?()-]/g, '')
      .trim()
  }

  /**
   * í˜ì´ì§€ êµ¬ë¶„ ì¶”ì •
   */
  private estimatePageBreaks(text: string): string[] {
    // ê°„ë‹¨í•œ í˜ì´ì§€ êµ¬ë¶„ íœ´ë¦¬ìŠ¤í‹±
    const pageBreakPatterns = [
      /\f/g,  // í¼ í”¼ë“œ ë¬¸ì
      /í˜ì´ì§€\s*\d+/gi,
      /Page\s*\d+/gi,
      /-\s*\d+\s*-/g  // í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´
    ]

    let pages = [text]
    
    for (const pattern of pageBreakPatterns) {
      const newPages = []
      for (const page of pages) {
        const splits = page.split(pattern)
        newPages.push(...splits.filter(split => split.trim().length > 50))
      }
      if (newPages.length > pages.length) {
        pages = newPages
        break
      }
    }
    
    return pages
  }

  /**
   * ë°”ì´ë„ˆë¦¬ì—ì„œ í”Œë ˆì¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìµœí›„ ìˆ˜ë‹¨)
   */
  private extractPlainTextFromBinary(uint8Array: Uint8Array): string {
    let text = ''
    
    // UTF-8ë¡œ ë””ì½”ë”© ì‹œë„
    try {
      const decoded = new TextDecoder('utf-8', { fatal: false }).decode(uint8Array)
      
      // ì¼ë°˜ í…ìŠ¤íŠ¸ íŒ¨í„´ ì¶”ì¶œ (ì˜ë¬¸, í•œê¸€, ìˆ«ì, ê¸°ë³¸ êµ¬ë‘ì )
      const textMatches = decoded.match(/[a-zA-Zê°€-í£0-9\s.,!?()/-]+/g)
      
      if (textMatches) {
        text = textMatches
          .filter(match => match.trim().length > 3)
          .join('\n')
          .substring(0, 10000) // ìµœëŒ€ ê¸¸ì´ ì œí•œ
      }
      
    } catch (error) {
      console.error('ë°”ì´ë„ˆë¦¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨:', error)
    }
    
    return text || 'í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
  }

  /**
   * DOCX íŒŒì¼ ì²˜ë¦¬ (JSZipì„ ì‚¬ìš©í•œ ì •í™•í•œ íŒŒì‹± - Railway ì „ìš©)
   */
  async extractTextFromDocx(
    docxBuffer: ArrayBuffer,
    fileName: string
  ): Promise<{
    text: string
    extraction_method: string
  }> {
    
    try {
      console.log(`ğŸ“„ DOCX íŒŒì‹± ì‹œì‘: ${fileName} (${docxBuffer.byteLength} bytes)`)
      
      // Railway í™˜ê²½ì—ì„œ JSZip ì‚¬ìš© ê°€ëŠ¥
      const JSZip = require('jszip')
      const zip = new JSZip()
      
      // DOCX íŒŒì¼ ë¡œë“œ (ZIPìœ¼ë¡œ ì••ì¶•ëœ XML íŒŒì¼ë“¤)
      const docxZip = await zip.loadAsync(docxBuffer)
      
      // document.xml íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
      const documentXml = docxZip.file('word/document.xml')
      
      if (!documentXml) {
        console.warn('âš ï¸ document.xmlì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ëŒ€ì•ˆ ë°©ë²• ì‹œë„')
        return this.extractDocxFallback(docxBuffer, fileName)
      }
      
      const xmlContent = await documentXml.async('string')
      console.log(`ğŸ“‹ document.xml ì¶”ì¶œ ì™„ë£Œ: ${xmlContent.length} bytes`)
      
      // Word XMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
      const extractedTexts = []
      
      // <w:t> íƒœê·¸ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Word ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ ëŸ°)
      const textMatches = xmlContent.match(/<w:t[^>]*>([^<]+)<\/w:t>/g)
      if (textMatches) {
        for (const match of textMatches) {
          const text = match.replace(/<[^>]+>/g, '').trim()
          if (text.length > 0) {
            extractedTexts.push(text)
          }
        }
      }
      
      // <w:p> íƒœê·¸ ë‹¨ìœ„ë¡œë„ ì¶”ì¶œ ì‹œë„ (ë‹¨ë½)
      const paragraphMatches = xmlContent.match(/<w:p[^>]*>.*?<\/w:p>/gs)
      if (paragraphMatches) {
        for (const paragraph of paragraphMatches) {
          const textInParagraph = paragraph.match(/<w:t[^>]*>([^<]*)<\/w:t>/g)
          if (textInParagraph) {
            const paragraphText = textInParagraph
              .map(t => t.replace(/<[^>]+>/g, ''))
              .join('')
              .trim()
            if (paragraphText.length > 0) {
              extractedTexts.push(paragraphText)
            }
          }
        }
      }
      
      // í…ìŠ¤íŠ¸ ì •ì œ ë° ê²°í•©
      const cleanText = extractedTexts
        .filter(text => text && text.trim().length > 1)
        .map(text => text.trim())
        .join(' ')
        .replace(/\s+/g, ' ')
        .replace(/&lt;/g, '<')
        .replace(/&gt;/g, '>')
        .replace(/&amp;/g, '&')
        .substring(0, 50000) // 50KB ì œí•œ
      
      console.log(`âœ… DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: ${cleanText.length}ì (JSZip ë°©ì‹)`)
      
      if (cleanText.length < 10) {
        console.warn('âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ, ëŒ€ì•ˆ ë°©ë²• ì‹œë„')
        return this.extractDocxFallback(docxBuffer, fileName)
      }
      
      return {
        text: cleanText,
        extraction_method: 'jszip_docx'
      }
      
    } catch (error) {
      console.error('âŒ JSZip DOCX íŒŒì‹± ì˜¤ë¥˜:', error)
      console.log('ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„...')
      return this.extractDocxFallback(docxBuffer, fileName)
    }
  }
  
  /**
   * DOCX ëŒ€ì•ˆ íŒŒì‹± ë°©ë²• (JSZip ì‹¤íŒ¨ì‹œ)
   */
  private async extractDocxFallback(
    docxBuffer: ArrayBuffer,
    fileName: string
  ): Promise<{
    text: string
    extraction_method: string
  }> {
    
    try {
      console.log(`ğŸ”„ DOCX ëŒ€ì•ˆ íŒŒì‹± ì‹œì‘: ${fileName}`)
      
      // ë°”ì´ë„ˆë¦¬ì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ íŒ¨í„´ ì°¾ê¸°
      const uint8Array = new Uint8Array(docxBuffer)
      const text = new TextDecoder('utf-8', { fatal: false }).decode(uint8Array)
      
      // ë” ì •êµí•œ XML í…ìŠ¤íŠ¸ íŒ¨í„´
      const patterns = [
        /<w:t[^>]*>([^<]+)<\/w:t>/g,
        /<text[^>]*>([^<]+)<\/text>/g,
        /\bword\/document\.xml.*?<w:t[^>]*>([^<]+)<\/w:t>/g,
        />[ê°€-í£a-zA-Z0-9\s.,!?():\-\/\[\]{}'"@#$%^&*+=<>~`|\\]{5,}<\/w:t>/g
      ]
      
      let extractedTexts = []
      
      for (const pattern of patterns) {
        const matches = [...text.matchAll(pattern)]
        extractedTexts.push(...matches.map(match => match[1] || match[0].replace(/<[^>]+>/g, '')))
      }
      
      const cleanText = extractedTexts
        .filter(text => text && text.trim().length > 3)
        .map(text => text.trim())
        .join(' ')
        .replace(/\s+/g, ' ')
        .substring(0, 20000)
      
      console.log(`ğŸ“‹ DOCX ëŒ€ì•ˆ íŒŒì‹± ì™„ë£Œ: ${cleanText.length}ì`)
      
      return {
        text: cleanText || `íŒŒì¼ëª… ê¸°ë°˜ ë¶„ì„: ${fileName}`,
        extraction_method: 'docx_fallback'
      }
      
    } catch (error) {
      console.error('âŒ DOCX ëŒ€ì•ˆ íŒŒì‹±ë„ ì‹¤íŒ¨:', error)
      return {
        text: `DOCX íŒŒì‹± ì‹¤íŒ¨ - íŒŒì¼: ${fileName}`,
        extraction_method: 'docx_error'
      }
    }
  }

  /**
   * ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
   */
  async analyzeDocumentStructure(
    text: string,
    fileName: string
  ): Promise<{
    sections: Array<{
      title: string
      content: string
      section_type: 'header' | 'body' | 'table' | 'list' | 'conclusion'
      word_count: number
    }>
    document_type: 'rfp' | 'proposal' | 'report' | 'presentation' | 'other'
    key_topics: string[]
    estimated_reading_time: number
  }> {
    
    console.log(`ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì‹œì‘: ${fileName}`)
    
    // ë¬¸ì„œ íƒ€ì… ì¶”ì •
    const documentType = this.estimateDocumentType(text, fileName)
    
    // ì„¹ì…˜ êµ¬ë¶„
    const sections = this.identifyDocumentSections(text)
    
    // í•µì‹¬ í† í”½ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
    const keyTopics = this.extractKeyTopics(text)
    
    // ì½ê¸° ì‹œê°„ ì¶”ì • (ë¶„ë‹¹ 200ë‹¨ì–´ ê¸°ì¤€)
    const wordCount = text.split(/\s+/).length
    const estimatedReadingTime = Math.ceil(wordCount / 200)
    
    console.log(`ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì™„ë£Œ: ${sections.length}ê°œ ì„¹ì…˜, ${keyTopics.length}ê°œ ì£¼ì œ`)
    
    return {
      sections,
      document_type: documentType,
      key_topics: keyTopics,
      estimated_reading_time: estimatedReadingTime
    }
  }

  /**
   * ë¬¸ì„œ íƒ€ì… ì¶”ì •
   */
  private estimateDocumentType(text: string, fileName: string): 'rfp' | 'proposal' | 'report' | 'presentation' | 'other' {
    const textLower = text.toLowerCase()
    const fileNameLower = fileName.toLowerCase()
    
    // RFP í‚¤ì›Œë“œ
    const rfpKeywords = ['request for proposal', 'rfp', 'ì œì•ˆìš”ì²­ì„œ', 'ì…ì°°ê³µê³ ', 'ì‚¬ì—…ê³„íš', 'ìš”êµ¬ì‚¬í•­', 'í‰ê°€ê¸°ì¤€']
    if (rfpKeywords.some(keyword => textLower.includes(keyword) || fileNameLower.includes(keyword))) {
      return 'rfp'
    }
    
    // ì œì•ˆì„œ í‚¤ì›Œë“œ
    const proposalKeywords = ['ì œì•ˆì„œ', 'proposal', 'ì‚¬ì—…ì œì•ˆ', 'ê¸°ìˆ ì œì•ˆ', 'ì†”ë£¨ì…˜', 'ë°©ì•ˆ', 'ì¶”ì§„ê³„íš']
    if (proposalKeywords.some(keyword => textLower.includes(keyword) || fileNameLower.includes(keyword))) {
      return 'proposal'
    }
    
    // ë³´ê³ ì„œ í‚¤ì›Œë“œ
    const reportKeywords = ['ë³´ê³ ì„œ', 'report', 'ë¶„ì„', 'ê²°ê³¼', 'í˜„í™©', 'ì‹¤ì ']
    if (reportKeywords.some(keyword => textLower.includes(keyword) || fileNameLower.includes(keyword))) {
      return 'report'
    }
    
    // ë°œí‘œìë£Œ í‚¤ì›Œë“œ
    const presentationKeywords = ['ë°œí‘œ', 'presentation', 'ppt', 'ì„¤ëª…ìë£Œ', 'ë¸Œë¦¬í•‘']
    if (presentationKeywords.some(keyword => textLower.includes(keyword) || fileNameLower.includes(keyword))) {
      return 'presentation'
    }
    
    return 'other'
  }

  /**
   * ë¬¸ì„œ ì„¹ì…˜ ì‹ë³„
   */
  private identifyDocumentSections(text: string): Array<{
    title: string
    content: string
    section_type: 'header' | 'body' | 'table' | 'list' | 'conclusion'
    word_count: number
  }> {
    
    const sections = []
    
    // ì„¹ì…˜ êµ¬ë¶„ íŒ¨í„´ (ì œëª©, ë²ˆí˜¸ ë“±)
    const sectionPatterns = [
      /^\d+\.\s+(.+)/gm,  // 1. ì œëª©
      /^ì œ\d+ì¥\s+(.+)/gm,  // ì œ1ì¥ ì œëª©
      /^[ê°€-í£]+\s*[:ï¼š]\s*(.+)/gm,  // ê°œìš”: ë‚´ìš©
      /^[A-Z][^\n]{10,50}/gm  // ì˜ë¬¸ ì œëª© íŒ¨í„´
    ]
    
    let currentSection = {
      title: 'ë¬¸ì„œ ì‹œì‘',
      content: '',
      section_type: 'body' as const,
      word_count: 0
    }
    
    const lines = text.split('\n')
    
    for (const line of lines) {
      const trimmedLine = line.trim()
      
      if (!trimmedLine) continue
      
      // ì„¹ì…˜ ì œëª© ê°ì§€
      let isNewSection = false
      for (const pattern of sectionPatterns) {
        const match = trimmedLine.match(pattern)
        if (match) {
          // ì´ì „ ì„¹ì…˜ ì €ì¥
          if (currentSection.content.trim()) {
            currentSection.word_count = currentSection.content.split(/\s+/).length
            sections.push({ ...currentSection })
          }
          
          // ìƒˆ ì„¹ì…˜ ì‹œì‘
          currentSection = {
            title: match[1] || trimmedLine,
            content: '',
            section_type: this.determineSectionType(trimmedLine),
            word_count: 0
          }
          isNewSection = true
          break
        }
      }
      
      if (!isNewSection) {
        currentSection.content += line + '\n'
      }
    }
    
    // ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
    if (currentSection.content.trim()) {
      currentSection.word_count = currentSection.content.split(/\s+/).length
      sections.push(currentSection)
    }
    
    return sections.length > 0 ? sections : [{
      title: 'ì „ì²´ ë¬¸ì„œ',
      content: text,
      section_type: 'body' as const,
      word_count: text.split(/\s+/).length
    }]
  }

  /**
   * ì„¹ì…˜ íƒ€ì… ê²°ì •
   */
  private determineSectionType(title: string): 'header' | 'body' | 'table' | 'list' | 'conclusion' {
    const titleLower = title.toLowerCase()
    
    if (titleLower.includes('ëª©ì°¨') || titleLower.includes('ì°¨ë¡€') || titleLower.includes('ê°œìš”')) {
      return 'header'
    }
    
    if (titleLower.includes('í‘œ') || titleLower.includes('table') || titleLower.includes('ë¹„êµ')) {
      return 'table'
    }
    
    if (titleLower.includes('ëª©ë¡') || titleLower.includes('list') || titleLower.includes('í•­ëª©')) {
      return 'list'
    }
    
    if (titleLower.includes('ê²°ë¡ ') || titleLower.includes('ë§ˆë¬´ë¦¬') || titleLower.includes('ìš”ì•½') || 
        titleLower.includes('conclusion') || titleLower.includes('summary')) {
      return 'conclusion'
    }
    
    return 'body'
  }

  /**
   * í•µì‹¬ í† í”½ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
   */
  private extractKeyTopics(text: string): string[] {
    // í•œêµ­ì–´ ë¶ˆìš©ì–´
    const stopWords = new Set([
      'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ë˜í•œ', 'ë”°ë¼ì„œ', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì´ì—', 'ëŒ€í•œ', 'ìœ„í•œ', 'í†µí•´', 'ëŒ€í•´',
      'ìˆëŠ”', 'ì—†ëŠ”', 'ë˜ëŠ”', 'í•˜ëŠ”', 'ê°™ì€', 'ë‹¤ë¥¸', 'ìƒˆë¡œìš´', 'ê¸°ë³¸', 'ì£¼ìš”', 'ì „ì²´', 'ì¼ë°˜', 'íŠ¹ë³„'
    ])
    
    // ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    const words = text
      .toLowerCase()
      .replace(/[^\wê°€-í£\s]/g, ' ')
      .split(/\s+/)
      .filter(word => word.length > 2 && !stopWords.has(word))
    
    const wordCount = new Map<string, number>()
    
    for (const word of words) {
      wordCount.set(word, (wordCount.get(word) || 0) + 1)
    }
    
    // ë¹ˆë„ ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
    return Array.from(wordCount.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10)
      .map(([word]) => word)
  }

  /**
   * íŒŒì¼ íƒ€ì… ê²€ì¦
   */
  validateFileType(buffer: ArrayBuffer, fileName: string): {
    isValid: boolean
    fileType: 'pdf' | 'docx' | 'txt' | 'unknown'
    mimeType: string
  } {
    const uint8Array = new Uint8Array(buffer)
    
    // PDF ì‹œê·¸ë‹ˆì²˜: %PDF
    if (uint8Array[0] === 0x25 && uint8Array[1] === 0x50 && 
        uint8Array[2] === 0x44 && uint8Array[3] === 0x46) {
      return {
        isValid: true,
        fileType: 'pdf',
        mimeType: 'application/pdf'
      }
    }
    
    // DOCX ì‹œê·¸ë‹ˆì²˜: PK (ZIP íŒŒì¼)
    if (uint8Array[0] === 0x50 && uint8Array[1] === 0x4B && fileName.endsWith('.docx')) {
      return {
        isValid: true,
        fileType: 'docx',
        mimeType: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
      }
    }

    // TXT íŒŒì¼ ê²€ì¦ (íŒŒì¼ í™•ì¥ìì™€ í…ìŠ¤íŠ¸ ë‚´ìš© ê²€ì‚¬)
    if (fileName.toLowerCase().endsWith('.txt')) {
      try {
        // UTF-8 í…ìŠ¤íŠ¸ì¸ì§€ ê²€ì¦
        const text = new TextDecoder('utf-8', { fatal: true }).decode(buffer)
        return {
          isValid: true,
          fileType: 'txt',
          mimeType: 'text/plain'
        }
      } catch (e) {
        // UTF-8 ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ê°„ì£¼
      }
    }
    
    return {
      isValid: false,
      fileType: 'unknown',
      mimeType: 'application/octet-stream'
    }
  }
}